
## CENTOS 
#yum -y install git java maven yum-utils
#yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
#yum-config-manager --add-repo  https://download.docker.com/linux/rhel/docker-ce.repo
#yum -y install docker-ce docker-ce-cli containerd.io docker-compose-plugin
#ln -s /usr/libexec/docker/cli-plugins/docker-compose /usr/local/bin/
#systemctl start docker

## UBUNTU
#apt-get update
apt-get install git
#apt-get install jdk*
#apt-get install maven
#update-alternatives --config java
#apt install docker*

#usermod -a -G docker <user>

export SR_DIR=/root
export SR_DIR=${SR_DIR}/selective-reprocessing

cd ${SR_DIR}
git clone https://github.com/doc-ti/selective-reprocessing.git

mkdir flume-input

cd ${SR_DIR}/java-flume
mvn clean install -Dmaven.wagon.http.ssl.insecure=true

cd ${SR_DIR}/java-storm
mvn clean install assembly:single -Dmaven.wagon.http.ssl.insecure=true

cd ${SR_DIR}
ln -s ../java-flume/target/plugin-flume-1.0.0.jar flume-conf/
ln -s ../java-storm/target/storm-test-1.2.2-dep.jar storm/

cd ${SR_DIR}
docker-compose up -d


docker exec -it kafka kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic_test
docker exec -it kafka01 kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic_data --replication-factor 2 --partitions 12

docker exec -it kafka01 kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic_data
Topic: topic_data       TopicId: 3X2lk1xeTdSbb8ncvXuHUg PartitionCount: 12      ReplicationFactor: 2    Configs: segment.bytes=1073741824
        Topic: topic_data       Partition: 0    Leader: 1       Replicas: 1,2   Isr: 1,2
        Topic: topic_data       Partition: 1    Leader: 2       Replicas: 2,3   Isr: 2,3
        Topic: topic_data       Partition: 2    Leader: 3       Replicas: 3,1   Isr: 3,1
        Topic: topic_data       Partition: 3    Leader: 1       Replicas: 1,3   Isr: 1,3
        Topic: topic_data       Partition: 4    Leader: 2       Replicas: 2,1   Isr: 2,1
        Topic: topic_data       Partition: 5    Leader: 3       Replicas: 3,2   Isr: 3,2
        Topic: topic_data       Partition: 6    Leader: 1       Replicas: 1,2   Isr: 1,2
        Topic: topic_data       Partition: 7    Leader: 2       Replicas: 2,3   Isr: 2,3
        Topic: topic_data       Partition: 8    Leader: 3       Replicas: 3,1   Isr: 3,1
        Topic: topic_data       Partition: 9    Leader: 1       Replicas: 1,3   Isr: 1,3
        Topic: topic_data       Partition: 10   Leader: 2       Replicas: 2,1   Isr: 2,1
        Topic: topic_data       Partition: 11   Leader: 3       Replicas: 3,2   Isr: 3,2


FFF=data_`date +%Y%m%d_%H%M%S`
export BASE=$RANDOM
for NN in `seq $BASE $((BASE+9))`
do
  echo $NN,$RANDOM
done > $FFF
ls -l $FFF
mv $FFF flume-input/

docker exec -it kafka kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic topic_data --from-beginning

docker exec -it mysql mysql -u root -prootpass -e "select * from info_files;" mydatabase 

docker exec -it supervisor storm jar /tmp/storm-test-1.2.2-dep.jar LoadTopology /tmp/topology.properties topology-load-data
docker exec -it supervisor storm kill  topology-load-data -w 5

docker exec -it supervisor bash



